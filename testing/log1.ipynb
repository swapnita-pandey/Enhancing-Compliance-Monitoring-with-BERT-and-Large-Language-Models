{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16007 entries, 0 to 16006\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   IP      16007 non-null  object\n",
      " 1   Time    16007 non-null  object\n",
      " 2   URL     16007 non-null  object\n",
      " 3   Staus   16007 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 500.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the \"weblog.csv\" dataset\n",
    "dataset_path = \"weblog.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Step 2: Inspect the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           IP                   Time  \\\n",
      "0  10.128.2.1  [29/Nov/2017:06:58:55   \n",
      "1  10.128.2.1  [29/Nov/2017:06:59:02   \n",
      "2  10.128.2.1  [29/Nov/2017:06:59:03   \n",
      "3  10.131.2.1  [29/Nov/2017:06:59:04   \n",
      "4  10.130.2.1  [29/Nov/2017:06:59:06   \n",
      "\n",
      "                                             URL Status  \n",
      "0                        GET /login.php HTTP/1.1    200  \n",
      "1                     POST /process.php HTTP/1.1    302  \n",
      "2                         GET /home.php HTTP/1.1    200  \n",
      "3          GET /js/vendor/moment.min.js HTTP/1.1    200  \n",
      "4  GET /bootstrap-3.3.7/js/bootstrap.js HTTP/1.1    200  \n"
     ]
    }
   ],
   "source": [
    "# Rename the \"Staus\" column to \"Status\"\n",
    "df.rename(columns={\"Staus\": \"Status\"}, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           IP                   Time  \\\n",
      "0  10.128.2.1  [29/Nov/2017:06:58:55   \n",
      "1  10.128.2.1  [29/Nov/2017:06:59:02   \n",
      "2  10.128.2.1  [29/Nov/2017:06:59:03   \n",
      "3  10.131.2.1  [29/Nov/2017:06:59:04   \n",
      "4  10.130.2.1  [29/Nov/2017:06:59:06   \n",
      "\n",
      "                                             URL Status  \n",
      "0                        GET /login.php HTTP/1.1    200  \n",
      "1                     POST /process.php HTTP/1.1    302  \n",
      "2                         GET /home.php HTTP/1.1    200  \n",
      "3          GET /js/vendor/moment.min.js HTTP/1.1    200  \n",
      "4  GET /bootstrap-3.3.7/js/bootstrap.js HTTP/1.1    200  \n"
     ]
    }
   ],
   "source": [
    "# Define a list of valid HTTP status codes\n",
    "valid_status_codes = ['200', '302', '304', '206', '404']\n",
    "\n",
    "# Filter out rows with invalid status codes\n",
    "df = df[df['Status'].isin(valid_status_codes)]\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['200' '302' '304' '206' '404']\n"
     ]
    }
   ],
   "source": [
    "status_values = df[\"Status\"].unique()\n",
    "print(status_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15789 entries, 0 to 16006\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   IP      15789 non-null  object\n",
      " 1   Time    15789 non-null  object\n",
      " 2   URL     15789 non-null  object\n",
      " 3   Status  15789 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 616.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Inspect the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows of the dataset:\n",
      "           IP                   Time  \\\n",
      "0  10.128.2.1  [29/Nov/2017:06:58:55   \n",
      "1  10.128.2.1  [29/Nov/2017:06:59:02   \n",
      "2  10.128.2.1  [29/Nov/2017:06:59:03   \n",
      "3  10.131.2.1  [29/Nov/2017:06:59:04   \n",
      "4  10.130.2.1  [29/Nov/2017:06:59:06   \n",
      "\n",
      "                                             URL Status  \n",
      "0                        GET /login.php HTTP/1.1    200  \n",
      "1                     POST /process.php HTTP/1.1    302  \n",
      "2                         GET /home.php HTTP/1.1    200  \n",
      "3          GET /js/vendor/moment.min.js HTTP/1.1    200  \n",
      "4  GET /bootstrap-3.3.7/js/bootstrap.js HTTP/1.1    200  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 3: Data Cleaning and Handling Missing Values\n",
    "df.dropna(inplace=True)  # Remove rows with missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        29/Nov/2017:06:58:55\n",
       "1        29/Nov/2017:06:59:02\n",
       "2        29/Nov/2017:06:59:03\n",
       "3        29/Nov/2017:06:59:04\n",
       "4        29/Nov/2017:06:59:06\n",
       "                 ...         \n",
       "16002    02/Mar/2018:15:47:12\n",
       "16003    02/Mar/2018:15:47:23\n",
       "16004    02/Mar/2018:15:47:32\n",
       "16005    02/Mar/2018:15:47:35\n",
       "16006    02/Mar/2018:15:47:46\n",
       "Name: Time, Length: 15789, dtype: object"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Time'] = df['Time'].str.replace('[', '', regex=False)\n",
    "df['Time']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        29/Nov/2017\n",
       "1        29/Nov/2017\n",
       "2        29/Nov/2017\n",
       "3        29/Nov/2017\n",
       "4        29/Nov/2017\n",
       "            ...     \n",
       "16002    02/Mar/2018\n",
       "16003    02/Mar/2018\n",
       "16004    02/Mar/2018\n",
       "16005    02/Mar/2018\n",
       "16006    02/Mar/2018\n",
       "Name: Date, Length: 15789, dtype: object"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_components = df['Time'].str.split(':', expand=True)\n",
    "df['Date'] = time_components[0]\n",
    "df['Date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        06\n",
       "1        06\n",
       "2        06\n",
       "3        06\n",
       "4        06\n",
       "         ..\n",
       "16002    15\n",
       "16003    15\n",
       "16004    15\n",
       "16005    15\n",
       "16006    15\n",
       "Name: TimeOfDay, Length: 15789, dtype: object"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TimeOfDay'] = time_components[1]\n",
    "df['TimeOfDay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original 'Time' column\n",
    "df.drop(columns=['Time'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode URLs\n",
    "df['URL_Encoded'] = label_encoder.fit_transform(df['URL'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode HTTP methods\n",
    "df['Method_Encoded'] = label_encoder.fit_transform(df['URL'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessed dataset:\n",
      "           IP                                            URL Status  \\\n",
      "0  10.128.2.1                        GET /login.php HTTP/1.1    200   \n",
      "1  10.128.2.1                     POST /process.php HTTP/1.1    302   \n",
      "2  10.128.2.1                         GET /home.php HTTP/1.1    200   \n",
      "3  10.131.2.1          GET /js/vendor/moment.min.js HTTP/1.1    200   \n",
      "4  10.130.2.1  GET /bootstrap-3.3.7/js/bootstrap.js HTTP/1.1    200   \n",
      "\n",
      "          Date TimeOfDay  URL_Encoded  Method_Encoded  \n",
      "0  29/Nov/2017        06          174             174  \n",
      "1  29/Nov/2017        06          289             289  \n",
      "2  29/Nov/2017        06          163             163  \n",
      "3  29/Nov/2017        06          172             172  \n",
      "4  29/Nov/2017        06           21              21  \n"
     ]
    }
   ],
   "source": [
    "# Display preprocessed data\n",
    "print(\"\\nPreprocessed dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining compliance rules and standards is a critical step in your project. You need to translate these rules into a structured format that can be understood by your system for automated analysis. Let's break down this step:\n",
    "\n",
    "Define Compliance Rules: Before writing code, make sure you have a clear understanding of the compliance rules and standards that you want to enforce. These could be related to data security, access controls, user privileges, system configurations, and more.\n",
    "\n",
    "Structured Format: You can represent each compliance rule in your dataset using a dictionary structure or a DataFrame. Each rule could have attributes like the rule description, the conditions to check, associated keywords, categories, and priority levels.\n",
    "\n",
    "Categorization and Priority: If your organization has different categories of compliance rules (e.g., security, privacy, operational), you can organize them accordingly. Similarly, you can assign priority levels to each rule to determine the severity of non-compliance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Rule Description  \\\n",
      "0  Ensure strong passwords are used   \n",
      "1     Monitor failed login attempts   \n",
      "2      Restrict unauthorized access   \n",
      "\n",
      "                                          Conditions  Keywords  \\\n",
      "0                    Password length >= 8 characters  password   \n",
      "1           Failed login attempts >= 5 within 1 hour     login   \n",
      "2  Access to sensitive data requires multi-factor...    access   \n",
      "\n",
      "         Category Priority  \n",
      "0        Security     High  \n",
      "1        Security   Medium  \n",
      "2  Access Control     High  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define compliance rules in a DataFrame\n",
    "compliance_rules = pd.DataFrame({\n",
    "    'Rule Description': [\n",
    "        'Ensure strong passwords are used',\n",
    "        'Monitor failed login attempts',\n",
    "        'Restrict unauthorized access'\n",
    "    ],\n",
    "    'Conditions': [\n",
    "        'Password length >= 8 characters',\n",
    "        'Failed login attempts >= 5 within 1 hour',\n",
    "        'Access to sensitive data requires multi-factor authentication'\n",
    "    ],\n",
    "    'Keywords': [\n",
    "        'password', 'login', 'access'\n",
    "    ],\n",
    "    'Category': [\n",
    "        'Security', 'Security', 'Access Control'\n",
    "    ],\n",
    "    'Priority': [\n",
    "        'High', 'Medium', 'High'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Display the compliance rules DataFrame\n",
    "print(compliance_rules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection and Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of the large language model (LLM) depends on the specific requirements of your project and the nature of the text data you're working with. bert-base-uncased is a commonly used LLM that is pretrained on a large corpus of text and is a good starting point for many NLP tasks. It's designed for uncased text, meaning all the text is lowercased before training, which can be helpful for tasks where the case of the words might not matter much.\n",
    "\n",
    "However, there are several other pre-trained LLMs available through the Hugging Face Transformers library that you can consider based on your project's requirements. Some alternatives include:\n",
    "\n",
    "bert-base-cased: Similar to bert-base-uncased, but retains the case of the text. This might be suitable if preserving the original case is important for your task.\n",
    "\n",
    "roberta-base: This is another popular model that is based on the BERT architecture but uses a modified training approach. It has shown strong performance on various NLP benchmarks.\n",
    "\n",
    "distilbert-base-uncased: This is a smaller and faster version of BERT that still provides competitive performance on various tasks. It's useful when computational resources are limited.\n",
    "\n",
    "xlnet-base-cased: XLNet is another architecture that has achieved state-of-the-art results on multiple NLP benchmarks. It's known for its autoregressive training approach.\n",
    "\n",
    "gpt2: While originally designed for text generation, GPT-2 can also be fine-tuned for classification tasks. It might be useful if you're interested in text generation alongside compliance classification.\n",
    "\n",
    "The choice of LLM should take into account factors such as model size, training data, computational resources, and task-specific requirements. It's recommended to experiment with different models and evaluate their performance on your specific dataset to determine the best fit for your compliance monitoring task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IP</th>\n",
       "      <th>Status</th>\n",
       "      <th>Date</th>\n",
       "      <th>TimeOfDay</th>\n",
       "      <th>URL_Encoded</th>\n",
       "      <th>Method_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.128.2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>29/Nov/2017</td>\n",
       "      <td>06</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.128.2.1</td>\n",
       "      <td>2</td>\n",
       "      <td>29/Nov/2017</td>\n",
       "      <td>06</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.128.2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>29/Nov/2017</td>\n",
       "      <td>06</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.131.2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>29/Nov/2017</td>\n",
       "      <td>06</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>29/Nov/2017</td>\n",
       "      <td>06</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           IP  Status         Date TimeOfDay  URL_Encoded  Method_Encoded\n",
       "0  10.128.2.1       0  29/Nov/2017        06          174             174\n",
       "1  10.128.2.1       2  29/Nov/2017        06          289             289\n",
       "2  10.128.2.1       0  29/Nov/2017        06          163             163\n",
       "3  10.131.2.1       0  29/Nov/2017        06          172             172\n",
       "4  10.130.2.1       0  29/Nov/2017        06           21              21"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define the number of classes based on the unique status values\n",
    "num_classes = 5\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_classes)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'YourDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[281], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m train_data, val_data \u001b[39m=\u001b[39m train_test_split(df, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# Create train and validation datasets using the data split\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m train_dataset \u001b[39m=\u001b[39m YourDataset(train_data, tokenizer, max_length\u001b[39m=\u001b[39mmax_seq_length)\n\u001b[0;32m      8\u001b[0m val_dataset \u001b[39m=\u001b[39m YourDataset(val_data, tokenizer, max_length\u001b[39m=\u001b[39mmax_seq_length)\n\u001b[0;32m     10\u001b[0m \u001b[39m# Define a range of hyperparameter values to search\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'YourDataset' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the preprocessed data into training and validation sets\n",
    "train_data, val_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create train and validation datasets using the data split\n",
    "train_dataset = YourDataset(train_data, tokenizer, max_length=max_seq_length)\n",
    "val_dataset = YourDataset(val_data, tokenizer, max_length=max_seq_length)\n",
    "\n",
    "# Define a range of hyperparameter values to search\n",
    "learning_rates = [1e-5, 2e-5, 3e-5]\n",
    "batch_sizes = [8, 16]\n",
    "epochs = [3, 4, 5]\n",
    "\n",
    "best_f1_score = 0.0\n",
    "best_hyperparameters = {}\n",
    "\n",
    "# Iterate through hyperparameter combinations\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        for ep in epochs:\n",
    "            training_args = TrainingArguments(\n",
    "                output_dir='./results',\n",
    "                learning_rate=lr,\n",
    "                per_device_train_batch_size=bs,\n",
    "                num_train_epochs=ep,\n",
    "                logging_dir='./logs',\n",
    "            )\n",
    "            \n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=val_dataset,  # Use the validation set for tuning\n",
    "                compute_metrics=compute_metrics,\n",
    "            )\n",
    "            \n",
    "            # Train the model\n",
    "            trainer.train()\n",
    "            \n",
    "            # Evaluate the model on the validation set\n",
    "            eval_results = trainer.evaluate()\n",
    "            val_f1_score = eval_results['eval_f1']\n",
    "            \n",
    "            # Check if this hyperparameter combination is the best so far\n",
    "            if val_f1_score > best_f1_score:\n",
    "                best_f1_score = val_f1_score\n",
    "                best_hyperparameters = {'learning_rate': lr, 'batch_size': bs, 'epochs': ep}\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[280], line 17\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m ep \u001b[39min\u001b[39;00m epochs:\n\u001b[0;32m      5\u001b[0m     training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[0;32m      6\u001b[0m         output_dir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./results\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m         learning_rate\u001b[39m=\u001b[39mlr,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m         logging_dir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./logs\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m     )\n\u001b[0;32m     13\u001b[0m     trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m     14\u001b[0m         model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m     15\u001b[0m         args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m     16\u001b[0m         train_dataset\u001b[39m=\u001b[39mtrain_dataset,\n\u001b[1;32m---> 17\u001b[0m         eval_dataset\u001b[39m=\u001b[39mval_dataset,\n\u001b[0;32m     18\u001b[0m         compute_metrics\u001b[39m=\u001b[39mcompute_metrics,\n\u001b[0;32m     19\u001b[0m     )\n\u001b[0;32m     21\u001b[0m     \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     trainer\u001b[39m.\u001b[39mtrain()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Iterate through hyperparameter combinations\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        for ep in epochs:\n",
    "            training_args = TrainingArguments(\n",
    "                output_dir='./results',\n",
    "                learning_rate=lr,\n",
    "                per_device_train_batch_size=bs,\n",
    "                num_train_epochs=ep,\n",
    "                logging_dir='./logs',\n",
    "            )\n",
    "            \n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=val_dataset,\n",
    "                compute_metrics=compute_metrics,\n",
    "            )\n",
    "            \n",
    "            # Train the model\n",
    "            trainer.train()\n",
    "            \n",
    "            # Evaluate the model on the validation set\n",
    "            eval_results = trainer.evaluate(val_dataset)\n",
    "            val_f1_score = eval_results['eval_f1']\n",
    "            \n",
    "            # Check if this hyperparameter combination is the best so far\n",
    "            if val_f1_score > best_f1_score:\n",
    "                best_f1_score = val_f1_score\n",
    "                best_hyperparameters = {'learning_rate': lr, 'batch_size': bs, 'epochs': ep}\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Define your LLM and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Convert labels to numeric format\n",
    "train_labels = train_labels.map({'200': 0, '302': 1, '304': 1, '206': 1, '404': 2})\n",
    "test_labels = test_labels.map({'200': 0, '302': 1, '304': 1, '206': 1, '404': 2})\n",
    "\n",
    "# Set num_labels parameter for model instantiation\n",
    "num_labels = 3  # Number of different classes\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df['URL'], df['Status'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input for Model: The resulting train_encodings and test_encodings are dictionaries containing the encoded sequences that the model can understand. These sequences include the input IDs (tokenized text), attention masks (to indicate which tokens should be attended to), and optionally token type IDs (useful for models like BERT).\n",
    "Now that you have your data tokenized and encoded, you're ready to proceed with the model training process. You can create PyTorch Dataset objects from these encodings and then train the model using the Trainer and TrainingArguments as explained in my previous response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode training texts\n",
    "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True)\n",
    "\n",
    "# Tokenize and encode test texts\n",
    "test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, return_tensors='pt', max_length=128)\n",
    "test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True, return_tensors='pt', max_length=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 2131, 1013,  ...,    0,    0,    0],\n",
      "        [ 101, 2131, 1013,  ...,    0,    0,    0],\n",
      "        [ 101, 2131, 1013,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2131, 1013,  ...,    0,    0,    0],\n",
      "        [ 101, 2695, 1013,  ...,    0,    0,    0],\n",
      "        [ 101, 2131, 1013,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "print(train_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 2131, 1013,  ...,    0,    0,    0],\n",
      "        [ 101, 2131, 1013,  ...,    0,    0,    0],\n",
      "        [ 101, 2131, 1013,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2131, 1013,  ...,    0,    0,    0],\n",
      "        [ 101, 2131, 1013,  ...,    0,    0,    0],\n",
      "        [ 101, 2131, 1013,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_encodings, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset objects\n",
    "train_dataset = CustomDataset(train_encodings, train_labels)\n",
    "test_dataset = CustomDataset(test_encodings, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Debugging: Print out relevant data around index 8992\\ndebug_index = 8992\\n\\n# Print the encoding and label for the debug index\\nprint(\"Debugging at index:\", debug_index)\\nprint(\"Encoding for index:\", debug_index)\\nprint(train_encodings[\"input_ids\"][debug_index])\\nprint(\"Label for index:\", debug_index)\\nprint(train_labels[debug_index])\\n\\n# Train the model\\ntrainer.train()'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Debugging: Print out relevant data around index 8992\n",
    "debug_index = 8992\n",
    "\n",
    "# Print the encoding and label for the debug index\n",
    "print(\"Debugging at index:\", debug_index)\n",
    "print(\"Encoding for index:\", debug_index)\n",
    "print(train_encodings[\"input_ids\"][debug_index])\n",
    "print(\"Label for index:\", debug_index)\n",
    "print(train_labels[debug_index])\n",
    "\n",
    "# Train the model\n",
    "trainer.train()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Remove row at index 8992\\ndf.drop(index=8992, inplace=True)\\n\\n# Reset the index after removing the row\\ndf.reset_index(drop=True, inplace=True)'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Remove row at index 8992\n",
    "df.drop(index=8992, inplace=True)\n",
    "\n",
    "# Reset the index after removing the row\n",
    "df.reset_index(drop=True, inplace=True)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    evaluation_strategy='epoch',\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    do_train=True,\n",
    "    do_eval=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\swapn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298ff3cfecee4208a819608a93b41f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4737 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swapn\\AppData\\Local\\Temp\\ipykernel_21632\\1277991774.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[192], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32mc:\\Users\\swapn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1534\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1536\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1537\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1538\u001b[0m )\n\u001b[1;32m-> 1539\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1540\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1541\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1542\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1543\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1544\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\swapn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:1787\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1784\u001b[0m     rng_to_sync \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m step \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m-> 1787\u001b[0m \u001b[39mfor\u001b[39;00m step, inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(epoch_iterator):\n\u001b[0;32m   1788\u001b[0m     total_batched_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1789\u001b[0m     \u001b[39mif\u001b[39;00m rng_to_sync:\n",
      "File \u001b[1;32mc:\\Users\\swapn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\data_loader.py:384\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 384\u001b[0m     current_batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(dataloader_iter)\n\u001b[0;32m    385\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     \u001b[39myield\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\swapn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\swapn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\swapn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\swapn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[186], line 11\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m     10\u001b[0m     item \u001b[39m=\u001b[39m {key: torch\u001b[39m.\u001b[39mtensor(val[idx]) \u001b[39mfor\u001b[39;00m key, val \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencodings\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m---> 11\u001b[0m     item[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabels[idx])\n\u001b[0;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m item\n",
      "\u001b[1;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "predictions = trainer.predict(test_encodings)\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "precision = precision_score(test_labels, predicted_labels)\n",
    "recall = recall_score(test_labels, predicted_labels)\n",
    "f1 = f1_score(test_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
